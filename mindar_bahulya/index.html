<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>
  </head>

  <body>
    <a-scene mindar-image="imageTargetSrc: targets.mind; uiScanning:no" color-space="sRGB"
             renderer="colorManagement: true, physicallyCorrectLights" vr-mode-ui="enabled: false"
             device-orientation-permission-ui="enabled: false">
        
      <!-- Load assets here -->
      <a-assets>
          <a-asset-item id="lighthouse" src="forUWCapstone_glb.glb"></a-asset-item>
          <a-asset-item id="porscheModel" src="porsche.glb"></a-asset-item>
          <a-asset-item id="houseModel" src="house.glb"></a-asset-item>
      </a-assets>

      <!-- Clickable Entity (house model - blue plane) -->
      <a-entity mindar-image-target="targetIndex: 0">
          <!-- <a-plane id="example-plane" class="clickable" color="blue" opacity="0.5" position="0 0 0" height="0.552" width="1" rotation="0 0 0"></a-plane> -->
          <a-gltf-model id="example-plane" class="clickable" rotation="0 0 0 " position="0 0 0" scale="0.15 0.15 0.15" src="#porscheModel">
      </a-entity>

      <a-entity mindar-image-target="targetIndex: 1" id="target1">
          <a-gltf-model id="lighthouseModel" class = "clickable" rotation="90 270 0 " position="0.5 0 0" scale="0.07 0.07 0.07" src="#lighthouse"></a-gltf-model>
          
          <!-- Play the audio when the target is detected -->
          <audio src="voiceover.mp3" id="voiceoverAudio"></audio>
          <audio src="ambient_noise.mp3" id="ambient_noise"></audio>
      </a-entity>

      <a-camera position="0 0 0" look-controls="enabled: false" cursor="fuse: false; rayOrigin: mouse;" raycaster="far: ${customFields.libVersion}; objects: .clickable"></a-camera>
    </a-scene>

    <script>
      // Clicking plane
      let a = 0;
      let isAudioPaused = false;
      document.addEventListener("DOMContentLoaded", function() {
        const examplePlane = document.querySelector('#example-plane');
        examplePlane.addEventListener("click", event => {
          console.log("model click " + a);
          a++; 
        });

        // Get the Lighthouse model
        const lighthouseModel = document.querySelector("#lighthouseModel");

        // Get the target element and model
        const target1 = document.querySelector("#target1");
        // const overlayModel = document.querySelector("#overlayModel");

        // Get the audio elements
        const voiceoverAudio = document.querySelector("#voiceoverAudio");
        const ambient_noise = document.querySelector("#ambient_noise");

        // Flags to check if audio is currently fading or playing
        let isAudioPlaying = false;

        // Function to fade audio in/out
        function fadeAudio(audioElement, fadeIn = true, duration = 2) {
            const steps = 20;
            const stepDuration = (duration * 1000) / steps;
            const stepChange = fadeIn ? 1 / steps : -1 / steps;

            // Adjust initial volume based on fade direction
            audioElement.volume = fadeIn ? 0 : 1;

            // Only play if fading in and not already playing
            if (fadeIn && !isAudioPlaying) {
                audioElement.play();
                isAudioPlaying = true;
            }

            // Begin fade interval
            const fadeInterval = setInterval(() => {
                audioElement.volume = Math.min(1, Math.max(0, audioElement.volume + stepChange));

                if ((fadeIn && audioElement.volume >= 1) || (!fadeIn && audioElement.volume <= 0)) {
                    clearInterval(fadeInterval);

                    // Stop audio on complete fade-out
                    if (!fadeIn) {
                        audioElement.pause();
                        // audioElement.currentTime = 0; // Reset to start for next play
                        isAudioPlaying = false;
                    }
                }
            }, stepDuration);
        }

        // Pause/Play the audio when interacted with the model
        lighthouseModel.addEventListener("click", event => {
          isAudioPaused = !isAudioPaused;
          if (isAudioPaused == true) {
            voiceoverAudio.pause();
            ambient_noise.pause();
          } else if (isAudioPaused == false) {
            voiceoverAudio.play();
            ambient_noise.play();
          }
          console.log("Pause: ", isAudioPaused);
        });

        // Show/hide model and fade audio when target is found/lost
        target1.addEventListener("targetFound", () => {
            // overlayModel.setAttribute("visible", "true"); // Show the model
            if (isAudioPaused == false) {
              fadeAudio(voiceoverAudio, true);  // Fade in voiceover
              fadeAudio(ambient_noise, true);   // Fade in ambient noise
            }
        });

        target1.addEventListener("targetLost", () => {
            // overlayModel.setAttribute("visible", "false"); // Hide the model
            if (isAudioPaused == false) {
              fadeAudio(voiceoverAudio, false); // Fade out voiceover
              fadeAudio(ambient_noise, false);  // Fade out ambient noise
            }
        });
        
      });
      
    </script>
  </body>
</html>